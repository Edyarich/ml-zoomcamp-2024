{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqCi2De3NShm",
    "outputId": "23eaf607-5304-41fd-ddc0-218e76546a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-12 09:31:25--  https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241212T093125Z&X-Amz-Expires=300&X-Amz-Signature=abc97ae1bcbdf2446055ac6516286958c0dd02c257ce2274dc36551a2b7f7f32&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-12-12 09:31:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/426348925/df5735c1-9082-4b67-968e-866f268793f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241212T093125Z&X-Amz-Expires=300&X-Amz-Signature=abc97ae1bcbdf2446055ac6516286958c0dd02c257ce2274dc36551a2b7f7f32&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmodel_2024_hairstyle.keras&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 160610502 (153M) [application/octet-stream]\n",
      "Saving to: ‘model_2024_hairstyle.keras’\n",
      "\n",
      "model_2024_hairstyl 100%[===================>] 153.17M   194MB/s    in 0.8s    \n",
      "\n",
      "2024-12-12 09:31:26 (194 MB/s) - ‘model_2024_hairstyle.keras’ saved [160610502/160610502]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/alexeygrigorev/large-datasets/releases/download/hairstyle/model_2024_hairstyle.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NsP-ahdlNUaz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 14:25:20.882156: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-12 14:25:20.917061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkh22_vy2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkh22_vy2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpkh22_vy2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  128601287269712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  128601286829152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  128601277925856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  128601277925680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  128601277998176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  128601277997824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1734002725.539873  276246 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1734002725.539902  276246 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-12-12 14:25:25.540417: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpkh22_vy2\n",
      "2024-12-12 14:25:25.540700: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-12-12 14:25:25.540705: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpkh22_vy2\n",
      "2024-12-12 14:25:25.543912: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-12-12 14:25:25.544573: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-12-12 14:25:25.620354: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpkh22_vy2\n",
      "2024-12-12 14:25:25.625889: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 85474 microseconds.\n",
      "2024-12-12 14:25:25.632395: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_2024_hairstyle.keras')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "duRFKDZINinr"
   },
   "outputs": [],
   "source": [
    "with open('model_2024_hairstyle.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXRn4g8bNuV1",
    "outputId": "c8cac139-fba0-4970-a329-44f28f291299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77M\tmodel_2024_hairstyle.tflite\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs model_2024_hairstyle.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RGbCQH7DNusB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='model_2024_hairstyle.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vlfD4gK-Nu-N",
    "outputId": "37f87565-db09-4b96-a0ad-fcfa91bdcf44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input_layer:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 200, 200,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 200, 200,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJZ3D7-8NvDp",
    "outputId": "6d949dea-dad3-4b86-d0cf-71cccac0c33f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall_1:0',\n",
       "  'index': 13,\n",
       "  'shape': array([1, 1], dtype=int32),\n",
       "  'shape_signature': array([-1,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ICOo7flTOvwi"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size, rescale):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    arr = np.array(img, dtype='float32')\n",
    "\n",
    "    arr *= rescale\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8zlc6743Owqq"
   },
   "outputs": [],
   "source": [
    "img = download_image('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg')\n",
    "img_processed = prepare_image(img, target_size=(200, 200), rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EVsy23gEQcDQ",
    "outputId": "864cb01a-ed68-4485-adfc-cbbd257fd8a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89377415]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "inp = np.array([img_processed])\n",
    "interpreter.set_tensor(input_index, inp)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "preds = interpreter.get_tensor(output_index)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "r-sAerwFRC1h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.py\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size, rescale):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    arr = np.array(img, dtype='float32')\n",
    "\n",
    "    arr *= rescale\n",
    "    return arr\n",
    "\n",
    "\n",
    "model = load_model('model_2024_hairstyle.keras')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('model_2024_hairstyle.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)\n",
    "\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path='model_2024_hairstyle.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "img = download_image('https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg')\n",
    "img_processed = prepare_image(img, target_size=(200, 200), rescale=1.0/255)\n",
    "inp = np.array([img_processed])\n",
    "interpreter.set_tensor(input_index, inp)\n",
    "interpreter.invoke()\n",
    "\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ymnik432/env)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
